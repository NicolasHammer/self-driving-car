{
  "nbformat": 4,
  "nbformat_minor": 2,
  "metadata": {
    "orig_nbformat": 4,
    "colab": {
      "name": "self_driving_notebook.ipynb",
      "provenance": []
    },
    "language_info": {
      "name": "python"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Simulated Self-Driving Car in Udacity"
      ],
      "metadata": {
        "id": "oQlfT9z6-EeH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Code for Google Colab to See Files"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "from os.path import exists\n",
        "from wheel.pep425tags import get_abbr_impl, get_impl_ver, get_abi_tag\n",
        "platform = '{}{}-{}'.format(get_abbr_impl(), get_impl_ver(), get_abi_tag())\n",
        "cuda_output = !ldconfig -p|grep cudart.so|sed -e 's/.*\\.\\([0-9]*\\)\\.\\([0-9]*\\)$/cu\\1\\2/'\n",
        "accelerator = cuda_output[0] if exists('/dev/nvidia0') else 'cpu'\n",
        "\n",
        "!pip install -q http://download.pytorch.org/whl/{accelerator}/torch-0.4.1-{platform}-linux_x86_64.whl torchvision\n",
        "!wget https://d17h27t6h515a5.cloudfront.net/topher/2016/December/584f6edd_data/data.zip"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "!unzip data.zip"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Import Files"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "source": [
        "# Import relevant packages\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils import data\n",
        "from torch.utils.data import DataLoader\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "import numpy as np\n",
        "import cv2\n",
        "\n",
        "import csv\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "outputs": [],
      "metadata": {
        "id": "U8lVBURMlg0q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Reading and Splitting the Data"
      ],
      "metadata": {
        "id": "NSSscv2W-OYF"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "source": [
        "# Read from the log file\n",
        "samples = []\n",
        "with open(\"data/driving_log.csv\") as csvfile:\n",
        "  reader = csv.reader(csvfile)\n",
        "  next(reader, None)\n",
        "  for line in reader:\n",
        "    samples.append(line)"
      ],
      "outputs": [],
      "metadata": {
        "id": "jroM4FBX8aHN"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "source": [
        "# Divide the data into training set and validation set\n",
        "train_len = int(0.8 * len(samples))\n",
        "valid_len = len(samples) - train_len \n",
        "train_samples, validation_samples = data.random_split(samples, lengths = [train_len, valid_len])"
      ],
      "outputs": [],
      "metadata": {
        "id": "oJj8TAXX-4Q4"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# Define function to move tensors to that device\n",
        "def toDevice(datas, device):\n",
        "    imgs, angles = datas\n",
        "    return imgs.float().to(device), angles.float().to(device)"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Loading Images in DataLoader"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "source": [
        "# Define the augmentation, transformation process, parameters, and dataset for\n",
        "# dataloader\n",
        "def augment(img_name: str, angle: float):\n",
        "  name = \"data/IMG/\" + img_name.split('/')[-1]\n",
        "  current_image = cv2.imread(name)\n",
        "  current_image = current_image[65:-25, :, :]\n",
        "  if np.random.rand() < 0.5:\n",
        "    current_image = cv2.flit(current_image, 1)\n",
        "    angle = -angle\n",
        "  return current_image, angle"
      ],
      "outputs": [],
      "metadata": {
        "id": "G9NNgHg__JFL"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "source": [
        "class Dataset(data.Dataset):\n",
        "\n",
        "    def __init__(self, samples, transform=None):\n",
        "        self.samples = samples\n",
        "        self.transform = transform\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        batch_samples = self.samples[index]\n",
        "        steering_angle = float(batch_samples[3])\n",
        "        center_img, steering_angle_center = augment(batch_samples[0], steering_angle)\n",
        "        left_img, steering_angle_left = augment(batch_samples[1], steering_angle + 0.4)\n",
        "        right_img, steering_angle_right = augment(batch_samples[2], steering_angle - 0.4)\n",
        "        center_img = self.transform(center_img)\n",
        "        left_img = self.transform(left_img)\n",
        "        right_img = self.transform(right_img)\n",
        "        return (center_img, steering_angle_center), (left_img, steering_angle_left), (right_img, steering_angle_right)\n",
        "      \n",
        "    def __len__(self):\n",
        "        return len(self.samples)"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "source": [
        "# Creating generator using the dataloader to parallasize the process\n",
        "transformations = transforms.Compose([transforms.Lambda(lambda x: (x / 255.0) - 0.5)])\n",
        "\n",
        "params = {'batch_size': 32,\n",
        "          'shuffle': True,\n",
        "          'num_workers': 4}\n",
        "\n",
        "training_set = Dataset(train_samples, transformations)\n",
        "training_generator = DataLoader(training_set, **params)\n",
        "\n",
        "validation_set = Dataset(validation_samples, transformations)\n",
        "validation_generator = DataLoader(validation_set, **params)"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model Architecture"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "source": [
        "# Define the network\n",
        "class NetworkLight(nn.Module):\n",
        "\n",
        "    def __init__(self):\n",
        "        super(NetworkLight, self).__init__()\n",
        "        self.conv_layers = nn.Sequential(\n",
        "            nn.Conv2d(3, 24, 3, stride=2),\n",
        "            nn.ELU(),\n",
        "            nn.Conv2d(24, 48, 3, stride=2),\n",
        "            nn.MaxPool2d(4, stride=4),\n",
        "            nn.Dropout(p=0.25)\n",
        "        )\n",
        "        self.linear_layers = nn.Sequential(\n",
        "            nn.Linear(in_features=48*4*19, out_features=50),\n",
        "            nn.ELU(),\n",
        "            nn.Linear(in_features=50, out_features=10),\n",
        "            nn.Linear(in_features=10, out_features=1)\n",
        "        )\n",
        "        \n",
        "\n",
        "    def forward(self, input):\n",
        "        input = input.view(input.size(0), 3, 70, 320)\n",
        "        output = self.conv_layers(input)\n",
        "        print(output.shape)\n",
        "        output = output.view(output.size(0), -1)\n",
        "        output = self.linear_layers(output)\n",
        "        return output"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Optimizer and Criterion"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "source": [
        "# Define optimizer\n",
        "model = NetworkLight()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.0001)\n",
        "\n",
        "criterion = nn.MSELoss()"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training and Validation"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "max_epochs = 22\n",
        "for epoch in range(max_epochs):\n",
        "    model.to(device)\n",
        "    \n",
        "    # Training\n",
        "    train_loss = 0\n",
        "    model.train()\n",
        "    for local_batch, (centers, lefts, rights) in enumerate(training_generator):\n",
        "        # Transfer to GPU\n",
        "        centers, lefts, rights = toDevice(centers, device), toDevice(lefts, device), toDevice(rights, device)\n",
        "        \n",
        "        # Model computations\n",
        "        optimizer.zero_grad()\n",
        "        datas = [centers, lefts, rights]        \n",
        "        for data in datas:\n",
        "            imgs, angles = data\n",
        "#             print(\"training image: \", imgs.shape)\n",
        "            outputs = model(imgs)\n",
        "            loss = criterion(outputs, angles.unsqueeze(1))\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            train_loss += loss.data[0].item()\n",
        "            \n",
        "        if local_batch % 100 == 0:\n",
        "            print('Loss: %.3f '\n",
        "                % (train_loss/(local_batch+1)))"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# Validation\n",
        "model.eval()\n",
        "valid_loss = 0\n",
        "with torch.set_grad_enabled(False):\n",
        "    for local_batch, (centers, lefts, rights) in enumerate(validation_generator):\n",
        "        # Transfer to GPU\n",
        "        centers, lefts, rights = toDevice(centers, device), toDevice(lefts, device), toDevice(rights, device)\n",
        "    \n",
        "        # Model computations\n",
        "        optimizer.zero_grad()\n",
        "        datas = [centers, lefts, rights]        \n",
        "        for data in datas:\n",
        "            imgs, angles = data\n",
        "#                 print(\"Validation image: \", imgs.shape)\n",
        "            outputs = model(imgs)\n",
        "            loss = criterion(outputs, angles.unsqueeze(1))\n",
        "            \n",
        "            valid_loss += loss.data[0].item()\n",
        "\n",
        "        if local_batch % 100 == 0:\n",
        "            print('Valid Loss: %.3f '\n",
        "                % (valid_loss/(local_batch+1)))"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Save Model"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# Define state and save the model wrt to state\n",
        "state = {\n",
        "        'model': model.module if device == 'cuda' else model,\n",
        "        }\n",
        "\n",
        "torch.save(state, 'model.h5')"
      ],
      "outputs": [],
      "metadata": {}
    }
  ]
}